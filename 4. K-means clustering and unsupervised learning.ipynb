{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color quantization example\n",
    "------------------------------\n",
    "Here's an example of K-means clustering on images. We're going to start with a couple of images, which live in the `datasets/kmeans/imgs` folder. \n",
    "\n",
    "We know that images often have a few dominant colors, e.g. the foreground color and the background color. In this example, we will write some code that uses `scikit-learn`'s K-means clustering algorithm to find the what these dominant colors may be.\n",
    "\n",
    "Once we know what the most important colors are in an image, we can compress the image (or \"quantize\", to use fancier terminology) by re-expressing the image using only the set of K colors that we get from the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set inline plots\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some useful imports\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "# You know what these are!\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is to help read in image files\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's list what images we have to work with\n",
    "imgs = os.listdir('datasets/kmeans/imgs/')\n",
    "print(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for now, let's use the first image\n",
    "img_path = os.path.join('datasets/kmeans/imgs/', imgs[1])\n",
    "print('Using image 0: path {}'.format(img_path))\n",
    "\n",
    "img = mpimg.imread(img_path)\n",
    "\n",
    "# normalize the image values\n",
    "img = img * 1.0 / img.max()\n",
    "\n",
    "imgplot = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An image is represented here as a three-dimensional array of floating-point numbers, which can take values from 0 to 1. If we look at ``img.shape``, we'll find that the first two dimensions are x and y, and then the last dimension is the color channel. There are three color channels (one each for red, green, and blue). A set of three channel values at a single (x, y)-coordinate is referred to as a \"pixel\".\n",
    "\n",
    "As per usual, we want to pick a small random sample of the data to train with. We're going to use a randomly selected 10% of the image to train our clusters with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Image shape: {}'.format(img.shape))\n",
    "width, height, num_channels = img.shape\n",
    "num_pixels = width * height\n",
    "num_sample_pixels = num_pixels / 10\n",
    "\n",
    "print('Sampling {} out of {} pixels'.format(num_sample_pixels, num_pixels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to reshape the image data into a single long array of pixels (instead of a two-dimensional array of pixels) in order to take our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_reshaped = np.reshape(img, (num_pixels, num_channels))\n",
    "img_sample = shuffle(img_reshaped, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some data, let's construct our K-means object and feed it some data. It will find the best K clusters, as determined by a distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We're going to try to find the 10 colors which best represent\n",
    "# the image, i.e. K = 10 clusters\n",
    "K = 10\n",
    "\n",
    "t0 = time()\n",
    "kmeans = KMeans(n_clusters=K, random_state=0)\n",
    "\n",
    "# Similar to the other scikit-learn code you've seen in the\n",
    "# past, we can call the fit() function to run the training\n",
    "# code (in this case, the clustering code). Unlike the\n",
    "# examples you've seen before, we don't need to pass in a Y\n",
    "# array, since K-means doesn't need any labels!\n",
    "\n",
    "kmeans.fit(img_sample)\n",
    "print(\"K-means clustering complete. Elapsed time: {} seconds\".format(time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The centers of each of the clusters represents a color that was significant in the image. We can grab the values of these colors from `kmeans.cluster_centers_`. We can also call `kmeans.predict()` to match each pixel in the image to the closest color, which will let us know the size of each cluster (and also serve as a way to quantize the image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As you can see, there are K cluster centers, each of which is a RGB color\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "labels = kmeans.predict(img_reshaped)\n",
    "print(\"K-means labeling complete. Elapsed time: {} seconds\".format(time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct a histogram of the points in each cluster\n",
    "n, bins, patches = plt.hist(labels, bins=range(K+1))\n",
    "\n",
    "# We're going to do a bit of magic to color the bins the right color\n",
    "for p, color in zip(patches, kmeans.cluster_centers_):\n",
    "    plt.setp(p, 'facecolor', color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might be able to tell from the above histogram, the most dominant color in the scene is the background color, followed by a large drop down to the foreground colors. Of course, this isn't particularly surprising, since visually we can see that the space is mostly filled with the background color -- that's why it's called the \"background\".\n",
    "\n",
    "Now, let's redraw the scene using only the cluster centers! This can be used for image compression, since we only need to store the index into the list of cluster centers and the colors corresponding to each center, rather than the colors corresponding to each pixel in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quantized_img = np.zeros(img.shape)\n",
    "for i in range(width):\n",
    "    for j in range(height):\n",
    "        # We need to do some math here to get the correct\n",
    "        # index position in the labels array\n",
    "        index = i * height + j\n",
    "        quantized_img[i][j] = kmeans.cluster_centers_[labels[index]]\n",
    "\n",
    "quantized_imgplot = plt.imshow(quantized_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the image looks almost the same, but that the gradients are no longer as smooth, and there are a few image artifacts scattered throughout. This is because we're only using the K best colors, which does not include the steps along the gradient.\n",
    "\n",
    "Try running the code through again with a different image, or with a larger (or smaller) value of K!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
